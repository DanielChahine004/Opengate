{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99792086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from numba import prange\n",
    "from numba import cuda\n",
    "import numpy as np\n",
    "import numba\n",
    "import math\n",
    "\n",
    "# Uniform attenuation\n",
    "attenuation = np.ones((128, 128, 128), dtype=np.float32)\n",
    "\n",
    "# Generate random LORs (for demonstration - replace with your simulated LORs)\n",
    "n_lors = 1_000_000  # Use smaller number for testing\n",
    "lors = np.random.randn(n_lors, 6).astype(np.float32) * 50  # Random LORs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e22bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def siddon(x1, y1, z1, x2, y2, z2, grid_size, voxel_size, grid_origin):\n",
    "    \"\"\"\n",
    "    Siddon's algorithm for ray-voxel intersection.\n",
    "    Returns arrays of voxel indices and intersection lengths.\n",
    "    \n",
    "    Parameters:\n",
    "    - (x1,y1,z1), (x2,y2,z2): LOR endpoints in mm\n",
    "    - grid_size: tuple (nx, ny, nz) - number of voxels\n",
    "    - voxel_size: float - voxel dimension in mm\n",
    "    - grid_origin: tuple (x0, y0, z0) - grid minimum corner in mm\n",
    "    \n",
    "    Returns:\n",
    "    - voxel_indices: array of linear indices\n",
    "    - lengths: array of intersection lengths in mm\n",
    "    - count: number of intersected voxels\n",
    "    \"\"\"\n",
    "    nx, ny, nz = grid_size\n",
    "    x0, y0, z0 = grid_origin\n",
    "    \n",
    "    # Direction vector\n",
    "    dx = x2 - x1\n",
    "    dy = y2 - y1\n",
    "    dz = z2 - z1\n",
    "    \n",
    "    # Ray length\n",
    "    ray_length = np.sqrt(dx*dx + dy*dy + dz*dz)\n",
    "    if ray_length < 1e-10:\n",
    "        return np.empty(0, dtype=np.int32), np.empty(0, dtype=np.float32), 0\n",
    "    \n",
    "    # Normalize direction\n",
    "    dx /= ray_length\n",
    "    dy /= ray_length\n",
    "    dz /= ray_length\n",
    "    \n",
    "    # Compute parametric t values for grid boundaries\n",
    "    # X boundaries\n",
    "    if abs(dx) > 1e-10:\n",
    "        tx_min = (x0 - x1) / dx\n",
    "        tx_max = (x0 + nx * voxel_size - x1) / dx\n",
    "        if tx_min > tx_max:\n",
    "            tx_min, tx_max = tx_max, tx_min\n",
    "    else:\n",
    "        tx_min = -1e10\n",
    "        tx_max = 1e10\n",
    "    \n",
    "    # Y boundaries\n",
    "    if abs(dy) > 1e-10:\n",
    "        ty_min = (y0 - y1) / dy\n",
    "        ty_max = (y0 + ny * voxel_size - y1) / dy\n",
    "        if ty_min > ty_max:\n",
    "            ty_min, ty_max = ty_max, ty_min\n",
    "    else:\n",
    "        ty_min = -1e10\n",
    "        ty_max = 1e10\n",
    "    \n",
    "    # Z boundaries\n",
    "    if abs(dz) > 1e-10:\n",
    "        tz_min = (z0 - z1) / dz\n",
    "        tz_max = (z0 + nz * voxel_size - z1) / dz\n",
    "        if tz_min > tz_max:\n",
    "            tz_min, tz_max = tz_max, tz_min\n",
    "    else:\n",
    "        tz_min = -1e10\n",
    "        tz_max = 1e10\n",
    "    \n",
    "    # Overall entry and exit parameters\n",
    "    t_min = max(max(tx_min, ty_min), tz_min)\n",
    "    t_max = min(min(tx_max, ty_max), tz_max)\n",
    "    \n",
    "    # Check if ray intersects grid\n",
    "    if t_min >= t_max or t_max < 0 or t_min > ray_length:\n",
    "        return np.empty(0, dtype=np.int32), np.empty(0, dtype=np.float32), 0\n",
    "    \n",
    "    # Clip to ray segment\n",
    "    t_min = max(t_min, 0.0)\n",
    "    t_max = min(t_max, ray_length)\n",
    "    \n",
    "    # Starting position\n",
    "    x_start = x1 + t_min * dx\n",
    "    y_start = y1 + t_min * dy\n",
    "    z_start = z1 + t_min * dz\n",
    "    \n",
    "    # Starting voxel indices\n",
    "    ix = int((x_start - x0) / voxel_size)\n",
    "    iy = int((y_start - y0) / voxel_size)\n",
    "    iz = int((z_start - z0) / voxel_size)\n",
    "    \n",
    "    # Clamp to grid\n",
    "    ix = max(0, min(ix, nx - 1))\n",
    "    iy = max(0, min(iy, ny - 1))\n",
    "    iz = max(0, min(iz, nz - 1))\n",
    "    \n",
    "    # Step directions\n",
    "    step_x = 1 if dx > 0 else -1\n",
    "    step_y = 1 if dy > 0 else -1\n",
    "    step_z = 1 if dz > 0 else -1\n",
    "    \n",
    "    # t values for next voxel boundaries\n",
    "    if abs(dx) > 1e-10:\n",
    "        if dx > 0:\n",
    "            t_next_x = ((ix + 1) * voxel_size + x0 - x1) / dx\n",
    "        else:\n",
    "            t_next_x = (ix * voxel_size + x0 - x1) / dx\n",
    "        t_delta_x = voxel_size / abs(dx)\n",
    "    else:\n",
    "        t_next_x = 1e10\n",
    "        t_delta_x = 1e10\n",
    "    \n",
    "    if abs(dy) > 1e-10:\n",
    "        if dy > 0:\n",
    "            t_next_y = ((iy + 1) * voxel_size + y0 - y1) / dy\n",
    "        else:\n",
    "            t_next_y = (iy * voxel_size + y0 - y1) / dy\n",
    "        t_delta_y = voxel_size / abs(dy)\n",
    "    else:\n",
    "        t_next_y = 1e10\n",
    "        t_delta_y = 1e10\n",
    "    \n",
    "    if abs(dz) > 1e-10:\n",
    "        if dz > 0:\n",
    "            t_next_z = ((iz + 1) * voxel_size + z0 - z1) / dz\n",
    "        else:\n",
    "            t_next_z = (iz * voxel_size + z0 - z1) / dz\n",
    "        t_delta_z = voxel_size / abs(dz)\n",
    "    else:\n",
    "        t_next_z = 1e10\n",
    "        t_delta_z = 1e10\n",
    "    \n",
    "    # Traverse voxels\n",
    "    max_voxels = nx + ny + nz\n",
    "    voxel_indices = np.empty(max_voxels, dtype=np.int32)\n",
    "    lengths = np.empty(max_voxels, dtype=np.float32)\n",
    "    count = 0\n",
    "    \n",
    "    t_current = t_min\n",
    "    \n",
    "    while t_current < t_max and count < max_voxels:\n",
    "        # Determine next boundary crossing\n",
    "        t_next = min(min(t_next_x, t_next_y), t_next_z)\n",
    "        t_next = min(t_next, t_max)\n",
    "        \n",
    "        # Length in current voxel\n",
    "        length = t_next - t_current\n",
    "        \n",
    "        if length > 1e-10:\n",
    "            voxel_indices[count] = ix + iy * nx + iz * nx * ny\n",
    "            lengths[count] = length\n",
    "            count += 1\n",
    "        \n",
    "        # Move to next voxel\n",
    "        if t_next >= t_max:\n",
    "            break\n",
    "        \n",
    "        if abs(t_next - t_next_x) < 1e-9:\n",
    "            ix += step_x\n",
    "            if ix < 0 or ix >= nx:\n",
    "                break\n",
    "            t_next_x += t_delta_x\n",
    "        \n",
    "        if abs(t_next - t_next_y) < 1e-9:\n",
    "            iy += step_y\n",
    "            if iy < 0 or iy >= ny:\n",
    "                break\n",
    "            t_next_y += t_delta_y\n",
    "        \n",
    "        if abs(t_next - t_next_z) < 1e-9:\n",
    "            iz += step_z\n",
    "            if iz < 0 or iz >= nz:\n",
    "                break\n",
    "            t_next_z += t_delta_z\n",
    "        \n",
    "        t_current = t_next\n",
    "    \n",
    "    return voxel_indices[:count], lengths[:count], count\n",
    "\n",
    "\n",
    "@numba.jit(nopython=True, parallel=True)\n",
    "def forward_project(lors, image, attenuation, grid_size, voxel_size, grid_origin):\n",
    "    \"\"\"\n",
    "    Forward projection with attenuation weighting.\n",
    "    \n",
    "    Returns:\n",
    "    - expected_counts: array of expected counts for each LOR\n",
    "    \"\"\"\n",
    "    n_lors = lors.shape[0]\n",
    "    expected = np.zeros(n_lors, dtype=np.float32)\n",
    "    \n",
    "    for i in prange(n_lors):\n",
    "        x1, y1, z1 = lors[i, 0], lors[i, 1], lors[i, 2]\n",
    "        x2, y2, z2 = lors[i, 3], lors[i, 4], lors[i, 5]\n",
    "        \n",
    "        voxels, lengths, count = siddon(x1, y1, z1, x2, y2, z2, \n",
    "                                        grid_size, voxel_size, grid_origin)\n",
    "        \n",
    "        val = 0.0\n",
    "        for j in range(count):\n",
    "            idx = voxels[j]\n",
    "            val += image[idx] * attenuation[idx] * lengths[j]\n",
    "        \n",
    "        expected[i] = val\n",
    "    \n",
    "    return expected\n",
    "\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def backproject_single(lor, ratio, attenuation, backproj, grid_size, voxel_size, grid_origin):\n",
    "    \"\"\"\n",
    "    Backprojection for a single LOR (called serially for thread safety).\n",
    "    \"\"\"\n",
    "    x1, y1, z1 = lor[0], lor[1], lor[2]\n",
    "    x2, y2, z2 = lor[3], lor[4], lor[5]\n",
    "    \n",
    "    voxels, lengths, count = siddon(x1, y1, z1, x2, y2, z2,\n",
    "                                    grid_size, voxel_size, grid_origin)\n",
    "    \n",
    "    for j in range(count):\n",
    "        idx = voxels[j]\n",
    "        backproj[idx] += ratio * attenuation[idx] * lengths[j]\n",
    "\n",
    "\n",
    "def backproject(lors, ratios, attenuation, backproj, grid_size, voxel_size, grid_origin):\n",
    "    \"\"\"\n",
    "    Backprojection with attenuation weighting.\n",
    "    Serial to avoid race conditions.\n",
    "    \"\"\"\n",
    "    n_lors = lors.shape[0]\n",
    "    for i in range(n_lors):\n",
    "        backproject_single(lors[i], ratios[i], attenuation, backproj,\n",
    "                          grid_size, voxel_size, grid_origin)\n",
    "\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def compute_sensitivity_single(lor, attenuation, sensitivity, grid_size, voxel_size, grid_origin):\n",
    "    \"\"\"\n",
    "    Compute sensitivity for a single LOR (called serially for thread safety).\n",
    "    \"\"\"\n",
    "    x1, y1, z1 = lor[0], lor[1], lor[2]\n",
    "    x2, y2, z2 = lor[3], lor[4], lor[5]\n",
    "    \n",
    "    voxels, lengths, count = siddon(x1, y1, z1, x2, y2, z2,\n",
    "                                    grid_size, voxel_size, grid_origin)\n",
    "    \n",
    "    for j in range(count):\n",
    "        idx = voxels[j]\n",
    "        sensitivity[idx] += attenuation[idx] * lengths[j]\n",
    "\n",
    "\n",
    "def compute_sensitivity(lors, attenuation, sensitivity, grid_size, voxel_size, grid_origin):\n",
    "    \"\"\"\n",
    "    Compute sensitivity map (normalization factor for OSEM).\n",
    "    Serial to avoid race conditions.\n",
    "    \"\"\"\n",
    "    n_lors = lors.shape[0]\n",
    "    for i in range(n_lors):\n",
    "        compute_sensitivity_single(lors[i], attenuation, sensitivity,\n",
    "                                  grid_size, voxel_size, grid_origin)\n",
    "        if (i + 1) % 100000 == 0:\n",
    "            print(f\"  Processed {i + 1}/{n_lors} LORs\")\n",
    "\n",
    "\n",
    "def osem_reconstruct(lors, attenuation, n_subsets=10, n_iterations=5, \n",
    "                     grid_size=(128, 128, 128), voxel_size=1.0):\n",
    "    \"\"\"\n",
    "    OSEM reconstruction for PET with attenuation correction.\n",
    "    \n",
    "    Parameters:\n",
    "    - lors: (N, 6) array of LOR endpoints [x1,y1,z1,x2,y2,z2] in mm\n",
    "    - attenuation: (128,128,128) attenuation map\n",
    "    - n_subsets: number of ordered subsets\n",
    "    - n_iterations: number of iterations\n",
    "    - grid_size: voxel grid dimensions\n",
    "    - voxel_size: voxel size in mm\n",
    "    \n",
    "    Returns:\n",
    "    - image: reconstructed activity image\n",
    "    - sensitivity: sensitivity map\n",
    "    \"\"\"\n",
    "    nx, ny, nz = grid_size\n",
    "    n_voxels = nx * ny * nz\n",
    "    grid_origin = (-64.0, -64.0, -64.0)  # Grid centered at origin\n",
    "    \n",
    "    # Initialize image (uniform)\n",
    "    image = np.ones(n_voxels, dtype=np.float32)\n",
    "    \n",
    "    # Flatten attenuation\n",
    "    attenuation_flat = attenuation.ravel().astype(np.float32)\n",
    "    \n",
    "    # Compute sensitivity map once\n",
    "    print(\"Computing sensitivity map...\")\n",
    "    sensitivity = np.zeros(n_voxels, dtype=np.float32)\n",
    "    compute_sensitivity(lors.astype(np.float32), attenuation_flat, sensitivity,\n",
    "                       grid_size, voxel_size, grid_origin)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    sensitivity = np.maximum(sensitivity, 1e-10)\n",
    "    \n",
    "    # Subset partitioning\n",
    "    n_lors = lors.shape[0]\n",
    "    subset_size = n_lors // n_subsets\n",
    "    \n",
    "    print(f\"Starting OSEM: {n_iterations} iterations, {n_subsets} subsets\")\n",
    "    print(f\"Total LORs: {n_lors}, LORs per subset: {subset_size}\")\n",
    "    \n",
    "    # Main OSEM loop\n",
    "    for iteration in range(n_iterations):\n",
    "        print(f\"Iteration {iteration + 1}/{n_iterations}\")\n",
    "        \n",
    "        for subset in range(n_subsets):\n",
    "            # Get subset of LORs\n",
    "            start_idx = subset * subset_size\n",
    "            end_idx = start_idx + subset_size if subset < n_subsets - 1 else n_lors\n",
    "            lors_subset = lors[start_idx:end_idx]\n",
    "            \n",
    "            # Forward projection\n",
    "            expected = forward_project(lors_subset.astype(np.float32), image, \n",
    "                                      attenuation_flat, grid_size, voxel_size, \n",
    "                                      grid_origin)\n",
    "            \n",
    "            # Compute ratios (measured = 1 for each LOR in list-mode)\n",
    "            expected = np.maximum(expected, 1e-10)  # Avoid division by zero\n",
    "            ratios = 1.0 / expected\n",
    "            \n",
    "            # Backprojection\n",
    "            backproj = np.zeros(n_voxels, dtype=np.float32)\n",
    "            backproject(lors_subset.astype(np.float32), ratios.astype(np.float32),\n",
    "                       attenuation_flat, backproj, grid_size, voxel_size, grid_origin)\n",
    "            \n",
    "            # Update image\n",
    "            image *= backproj / sensitivity\n",
    "            \n",
    "            print(f\"  Subset {subset + 1}/{n_subsets} complete\")\n",
    "    \n",
    "    # Reshape to 3D\n",
    "    image_3d = image.reshape(grid_size)\n",
    "    sensitivity_3d = sensitivity.reshape(grid_size)\n",
    "    \n",
    "    return image_3d, sensitivity_3d\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate example data\n",
    "    print(\"Generating example data...\")\n",
    "    \n",
    "    # Create simple phantom (sphere in center)\n",
    "    phantom = np.zeros((128, 128, 128), dtype=np.float32)\n",
    "    for i in range(128):\n",
    "        for j in range(128):\n",
    "            for k in range(128):\n",
    "                r = np.sqrt((i-64)**2 + (j-64)**2 + (k-64)**2)\n",
    "                if r < 30:\n",
    "                    phantom[i, j, k] = 1.0\n",
    "    \n",
    "    # Run OSEM\n",
    "    reconstructed, sensitivity = osem_reconstruct(lors, attenuation, \n",
    "                                                   n_subsets=10, n_iterations=3)\n",
    "    \n",
    "    print(f\"Reconstruction complete!\")\n",
    "    print(f\"Image shape: {reconstructed.shape}\")\n",
    "    print(f\"Image range: [{reconstructed.min():.3f}, {reconstructed.max():.3f}]\")\n",
    "\n",
    "    # Display central slice\n",
    "    plt.imshow(reconstructed[:, :, 64], cmap='hot')\n",
    "    plt.colorbar()\n",
    "    plt.title('Central Slice of Reconstructed Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edeff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit(device=True)\n",
    "def siddon_cuda(x1, y1, z1, x2, y2, z2, grid_size, voxel_size, grid_origin,\n",
    "                voxel_indices, lengths):\n",
    "    \"\"\"\n",
    "    Siddon's algorithm for CUDA (device function).\n",
    "    Returns count of intersected voxels.\n",
    "    Arrays voxel_indices and lengths must be preallocated.\n",
    "    \"\"\"\n",
    "    nx, ny, nz = grid_size\n",
    "    x0, y0, z0 = grid_origin\n",
    "    \n",
    "    # Direction vector\n",
    "    dx = x2 - x1\n",
    "    dy = y2 - y1\n",
    "    dz = z2 - z1\n",
    "    \n",
    "    # Ray length\n",
    "    ray_length = math.sqrt(dx*dx + dy*dy + dz*dz)\n",
    "    if ray_length < 1e-10:\n",
    "        return 0\n",
    "    \n",
    "    # Normalize direction\n",
    "    dx /= ray_length\n",
    "    dy /= ray_length\n",
    "    dz /= ray_length\n",
    "    \n",
    "    # Compute parametric t values for grid boundaries\n",
    "    if abs(dx) > 1e-10:\n",
    "        tx_min = (x0 - x1) / dx\n",
    "        tx_max = (x0 + nx * voxel_size - x1) / dx\n",
    "        if tx_min > tx_max:\n",
    "            tx_min, tx_max = tx_max, tx_min\n",
    "    else:\n",
    "        tx_min = -1e10\n",
    "        tx_max = 1e10\n",
    "    \n",
    "    if abs(dy) > 1e-10:\n",
    "        ty_min = (y0 - y1) / dy\n",
    "        ty_max = (y0 + ny * voxel_size - y1) / dy\n",
    "        if ty_min > ty_max:\n",
    "            ty_min, ty_max = ty_max, ty_min\n",
    "    else:\n",
    "        ty_min = -1e10\n",
    "        ty_max = 1e10\n",
    "    \n",
    "    if abs(dz) > 1e-10:\n",
    "        tz_min = (z0 - z1) / dz\n",
    "        tz_max = (z0 + nz * voxel_size - z1) / dz\n",
    "        if tz_min > tz_max:\n",
    "            tz_min, tz_max = tz_max, tz_min\n",
    "    else:\n",
    "        tz_min = -1e10\n",
    "        tz_max = 1e10\n",
    "    \n",
    "    # Overall entry and exit\n",
    "    t_min = max(max(tx_min, ty_min), tz_min)\n",
    "    t_max = min(min(tx_max, ty_max), tz_max)\n",
    "    \n",
    "    if t_min >= t_max or t_max < 0 or t_min > ray_length:\n",
    "        return 0\n",
    "    \n",
    "    t_min = max(t_min, 0.0)\n",
    "    t_max = min(t_max, ray_length)\n",
    "    \n",
    "    # Starting position\n",
    "    x_start = x1 + t_min * dx\n",
    "    y_start = y1 + t_min * dy\n",
    "    z_start = z1 + t_min * dz\n",
    "    \n",
    "    # Starting voxel\n",
    "    ix = int((x_start - x0) / voxel_size)\n",
    "    iy = int((y_start - y0) / voxel_size)\n",
    "    iz = int((z_start - z0) / voxel_size)\n",
    "    \n",
    "    ix = max(0, min(ix, nx - 1))\n",
    "    iy = max(0, min(iy, ny - 1))\n",
    "    iz = max(0, min(iz, nz - 1))\n",
    "    \n",
    "    # Step directions\n",
    "    step_x = 1 if dx > 0 else -1\n",
    "    step_y = 1 if dy > 0 else -1\n",
    "    step_z = 1 if dz > 0 else -1\n",
    "    \n",
    "    # Next boundary t values\n",
    "    if abs(dx) > 1e-10:\n",
    "        if dx > 0:\n",
    "            t_next_x = ((ix + 1) * voxel_size + x0 - x1) / dx\n",
    "        else:\n",
    "            t_next_x = (ix * voxel_size + x0 - x1) / dx\n",
    "        t_delta_x = voxel_size / abs(dx)\n",
    "    else:\n",
    "        t_next_x = 1e10\n",
    "        t_delta_x = 1e10\n",
    "    \n",
    "    if abs(dy) > 1e-10:\n",
    "        if dy > 0:\n",
    "            t_next_y = ((iy + 1) * voxel_size + y0 - y1) / dy\n",
    "        else:\n",
    "            t_next_y = (iy * voxel_size + y0 - y1) / dy\n",
    "        t_delta_y = voxel_size / abs(dy)\n",
    "    else:\n",
    "        t_next_y = 1e10\n",
    "        t_delta_y = 1e10\n",
    "    \n",
    "    if abs(dz) > 1e-10:\n",
    "        if dz > 0:\n",
    "            t_next_z = ((iz + 1) * voxel_size + z0 - z1) / dz\n",
    "        else:\n",
    "            t_next_z = (iz * voxel_size + z0 - z1) / dz\n",
    "        t_delta_z = voxel_size / abs(dz)\n",
    "    else:\n",
    "        t_next_z = 1e10\n",
    "        t_delta_z = 1e10\n",
    "    \n",
    "    # Traverse voxels\n",
    "    count = 0\n",
    "    t_current = t_min\n",
    "    max_voxels = len(voxel_indices)\n",
    "    \n",
    "    while t_current < t_max and count < max_voxels:\n",
    "        t_next = min(min(t_next_x, t_next_y), t_next_z)\n",
    "        t_next = min(t_next, t_max)\n",
    "        \n",
    "        length = t_next - t_current\n",
    "        \n",
    "        if length > 1e-10:\n",
    "            voxel_indices[count] = ix + iy * nx + iz * nx * ny\n",
    "            lengths[count] = length\n",
    "            count += 1\n",
    "        \n",
    "        if t_next >= t_max:\n",
    "            break\n",
    "        \n",
    "        if abs(t_next - t_next_x) < 1e-9:\n",
    "            ix += step_x\n",
    "            if ix < 0 or ix >= nx:\n",
    "                break\n",
    "            t_next_x += t_delta_x\n",
    "        \n",
    "        if abs(t_next - t_next_y) < 1e-9:\n",
    "            iy += step_y\n",
    "            if iy < 0 or iy >= ny:\n",
    "                break\n",
    "            t_next_y += t_delta_y\n",
    "        \n",
    "        if abs(t_next - t_next_z) < 1e-9:\n",
    "            iz += step_z\n",
    "            if iz < 0 or iz >= nz:\n",
    "                break\n",
    "            t_next_z += t_delta_z\n",
    "        \n",
    "        t_current = t_next\n",
    "    \n",
    "    return count\n",
    "\n",
    "\n",
    "@cuda.jit\n",
    "def forward_project_kernel(lors, image, attenuation, expected, \n",
    "                          nx, ny, nz, voxel_size, x0, y0, z0):\n",
    "    \"\"\"\n",
    "    CUDA kernel for forward projection.\n",
    "    Each thread processes one LOR.\n",
    "    \"\"\"\n",
    "    idx = cuda.grid(1)\n",
    "    \n",
    "    if idx >= lors.shape[0]:\n",
    "        return\n",
    "    \n",
    "    # Allocate shared arrays for this thread\n",
    "    voxels = cuda.local.array(200, numba.int32)\n",
    "    lens = cuda.local.array(200, numba.float32)\n",
    "    \n",
    "    x1 = lors[idx, 0]\n",
    "    y1 = lors[idx, 1]\n",
    "    z1 = lors[idx, 2]\n",
    "    x2 = lors[idx, 3]\n",
    "    y2 = lors[idx, 4]\n",
    "    z2 = lors[idx, 5]\n",
    "    \n",
    "    count = siddon_cuda(x1, y1, z1, x2, y2, z2, \n",
    "                       (nx, ny, nz), voxel_size, (x0, y0, z0),\n",
    "                       voxels, lens)\n",
    "    \n",
    "    val = 0.0\n",
    "    for i in range(count):\n",
    "        v_idx = voxels[i]\n",
    "        val += image[v_idx] * attenuation[v_idx] * lens[i]\n",
    "    \n",
    "    expected[idx] = val\n",
    "\n",
    "\n",
    "@cuda.jit\n",
    "def backproject_kernel(lors, ratios, attenuation, backproj,\n",
    "                      nx, ny, nz, voxel_size, x0, y0, z0):\n",
    "    \"\"\"\n",
    "    CUDA kernel for backprojection.\n",
    "    Uses atomic add for thread safety.\n",
    "    \"\"\"\n",
    "    idx = cuda.grid(1)\n",
    "    \n",
    "    if idx >= lors.shape[0]:\n",
    "        return\n",
    "    \n",
    "    voxels = cuda.local.array(200, numba.int32)\n",
    "    lens = cuda.local.array(200, numba.float32)\n",
    "    \n",
    "    x1 = lors[idx, 0]\n",
    "    y1 = lors[idx, 1]\n",
    "    z1 = lors[idx, 2]\n",
    "    x2 = lors[idx, 3]\n",
    "    y2 = lors[idx, 4]\n",
    "    z2 = lors[idx, 5]\n",
    "    \n",
    "    count = siddon_cuda(x1, y1, z1, x2, y2, z2,\n",
    "                       (nx, ny, nz), voxel_size, (x0, y0, z0),\n",
    "                       voxels, lens)\n",
    "    \n",
    "    ratio = ratios[idx]\n",
    "    for i in range(count):\n",
    "        v_idx = voxels[i]\n",
    "        val = ratio * attenuation[v_idx] * lens[i]\n",
    "        cuda.atomic.add(backproj, v_idx, val)\n",
    "\n",
    "\n",
    "@cuda.jit\n",
    "def sensitivity_kernel(lors, attenuation, sensitivity,\n",
    "                      nx, ny, nz, voxel_size, x0, y0, z0):\n",
    "    \"\"\"\n",
    "    CUDA kernel for sensitivity computation.\n",
    "    \"\"\"\n",
    "    idx = cuda.grid(1)\n",
    "    \n",
    "    if idx >= lors.shape[0]:\n",
    "        return\n",
    "    \n",
    "    voxels = cuda.local.array(200, numba.int32)\n",
    "    lens = cuda.local.array(200, numba.float32)\n",
    "    \n",
    "    x1 = lors[idx, 0]\n",
    "    y1 = lors[idx, 1]\n",
    "    z1 = lors[idx, 2]\n",
    "    x2 = lors[idx, 3]\n",
    "    y2 = lors[idx, 4]\n",
    "    z2 = lors[idx, 5]\n",
    "    \n",
    "    count = siddon_cuda(x1, y1, z1, x2, y2, z2,\n",
    "                       (nx, ny, nz), voxel_size, (x0, y0, z0),\n",
    "                       voxels, lens)\n",
    "    \n",
    "    for i in range(count):\n",
    "        v_idx = voxels[i]\n",
    "        val = attenuation[v_idx] * lens[i]\n",
    "        cuda.atomic.add(sensitivity, v_idx, val)\n",
    "\n",
    "\n",
    "def forward_project_gpu(lors, image, attenuation, grid_size, voxel_size, \n",
    "                       grid_origin, batch_size=100000):\n",
    "    \"\"\"\n",
    "    Forward projection on GPU with batching.\n",
    "    \"\"\"\n",
    "    n_lors = lors.shape[0]\n",
    "    n_voxels = np.prod(grid_size)\n",
    "    expected = np.zeros(n_lors, dtype=np.float32)\n",
    "    \n",
    "    # Transfer image and attenuation to GPU once\n",
    "    d_image = cuda.to_device(image.astype(np.float32))\n",
    "    d_attenuation = cuda.to_device(attenuation.astype(np.float32))\n",
    "    \n",
    "    nx, ny, nz = grid_size\n",
    "    x0, y0, z0 = grid_origin\n",
    "    \n",
    "    # Process in batches\n",
    "    threads_per_block = 256\n",
    "    \n",
    "    for start_idx in range(0, n_lors, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, n_lors)\n",
    "        batch_lors = lors[start_idx:end_idx]\n",
    "        n_batch = batch_lors.shape[0]\n",
    "        \n",
    "        # Transfer batch to GPU\n",
    "        d_lors = cuda.to_device(batch_lors.astype(np.float32))\n",
    "        d_expected = cuda.device_array(n_batch, dtype=np.float32)\n",
    "        \n",
    "        # Launch kernel\n",
    "        blocks_per_grid = (n_batch + threads_per_block - 1) // threads_per_block\n",
    "        forward_project_kernel[blocks_per_grid, threads_per_block](\n",
    "            d_lors, d_image, d_attenuation, d_expected,\n",
    "            nx, ny, nz, voxel_size, x0, y0, z0\n",
    "        )\n",
    "        \n",
    "        # Copy back\n",
    "        expected[start_idx:end_idx] = d_expected.copy_to_host()\n",
    "    \n",
    "    return expected\n",
    "\n",
    "\n",
    "def backproject_gpu(lors, ratios, attenuation, grid_size, voxel_size,\n",
    "                   grid_origin, batch_size=100000):\n",
    "    \"\"\"\n",
    "    Backprojection on GPU with batching.\n",
    "    \"\"\"\n",
    "    n_lors = lors.shape[0]\n",
    "    n_voxels = np.prod(grid_size)\n",
    "    backproj = np.zeros(n_voxels, dtype=np.float32)\n",
    "    \n",
    "    # GPU arrays\n",
    "    d_attenuation = cuda.to_device(attenuation.astype(np.float32))\n",
    "    d_backproj = cuda.to_device(backproj)\n",
    "    \n",
    "    nx, ny, nz = grid_size\n",
    "    x0, y0, z0 = grid_origin\n",
    "    \n",
    "    threads_per_block = 256\n",
    "    \n",
    "    for start_idx in range(0, n_lors, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, n_lors)\n",
    "        batch_lors = lors[start_idx:end_idx]\n",
    "        batch_ratios = ratios[start_idx:end_idx]\n",
    "        n_batch = batch_lors.shape[0]\n",
    "        \n",
    "        d_lors = cuda.to_device(batch_lors.astype(np.float32))\n",
    "        d_ratios = cuda.to_device(batch_ratios.astype(np.float32))\n",
    "        \n",
    "        blocks_per_grid = (n_batch + threads_per_block - 1) // threads_per_block\n",
    "        backproject_kernel[blocks_per_grid, threads_per_block](\n",
    "            d_lors, d_ratios, d_attenuation, d_backproj,\n",
    "            nx, ny, nz, voxel_size, x0, y0, z0\n",
    "        )\n",
    "    \n",
    "    return d_backproj.copy_to_host()\n",
    "\n",
    "\n",
    "def compute_sensitivity_gpu(lors, attenuation, grid_size, voxel_size,\n",
    "                           grid_origin, batch_size=100000):\n",
    "    \"\"\"\n",
    "    Compute sensitivity map on GPU with batching.\n",
    "    \"\"\"\n",
    "    n_lors = lors.shape[0]\n",
    "    n_voxels = np.prod(grid_size)\n",
    "    sensitivity = np.zeros(n_voxels, dtype=np.float32)\n",
    "    \n",
    "    d_attenuation = cuda.to_device(attenuation.astype(np.float32))\n",
    "    d_sensitivity = cuda.to_device(sensitivity)\n",
    "    \n",
    "    nx, ny, nz = grid_size\n",
    "    x0, y0, z0 = grid_origin\n",
    "    \n",
    "    threads_per_block = 256\n",
    "    \n",
    "    for start_idx in range(0, n_lors, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, n_lors)\n",
    "        batch_lors = lors[start_idx:end_idx]\n",
    "        n_batch = batch_lors.shape[0]\n",
    "        \n",
    "        d_lors = cuda.to_device(batch_lors.astype(np.float32))\n",
    "        \n",
    "        blocks_per_grid = (n_batch + threads_per_block - 1) // threads_per_block\n",
    "        sensitivity_kernel[blocks_per_grid, threads_per_block](\n",
    "            d_lors, d_attenuation, d_sensitivity,\n",
    "            nx, ny, nz, voxel_size, x0, y0, z0\n",
    "        )\n",
    "        \n",
    "        if (end_idx) % 1000000 == 0 or end_idx == n_lors:\n",
    "            print(f\"  Processed {end_idx}/{n_lors} LORs\")\n",
    "    \n",
    "    return d_sensitivity.copy_to_host()\n",
    "\n",
    "\n",
    "def osem_reconstruct_gpu(lors, attenuation, n_subsets=10, n_iterations=5,\n",
    "                        grid_size=(128, 128, 128), voxel_size=1.0,\n",
    "                        batch_size=100000):\n",
    "    \"\"\"\n",
    "    OSEM reconstruction for PET on GPU.\n",
    "    \n",
    "    Parameters:\n",
    "    - lors: (N, 6) array of LOR endpoints [x1,y1,z1,x2,y2,z2] in mm\n",
    "    - attenuation: (128,128,128) attenuation map\n",
    "    - n_subsets: number of ordered subsets\n",
    "    - n_iterations: number of iterations\n",
    "    - grid_size: voxel grid dimensions\n",
    "    - voxel_size: voxel size in mm\n",
    "    - batch_size: LORs per GPU batch (adjust based on GPU memory)\n",
    "    \n",
    "    Returns:\n",
    "    - image: reconstructed activity image\n",
    "    - sensitivity: sensitivity map\n",
    "    \"\"\"\n",
    "    nx, ny, nz = grid_size\n",
    "    n_voxels = nx * ny * nz\n",
    "    grid_origin = (-64.0, -64.0, -64.0)\n",
    "    \n",
    "    # Initialize\n",
    "    image = np.ones(n_voxels, dtype=np.float32)\n",
    "    attenuation_flat = attenuation.ravel().astype(np.float32)\n",
    "    \n",
    "    # Compute sensitivity\n",
    "    print(\"Computing sensitivity map on GPU...\")\n",
    "    sensitivity = compute_sensitivity_gpu(lors, attenuation_flat, grid_size,\n",
    "                                         voxel_size, grid_origin, batch_size)\n",
    "    sensitivity = np.maximum(sensitivity, 1e-10)\n",
    "    \n",
    "    # Subset partitioning\n",
    "    n_lors = lors.shape[0]\n",
    "    subset_size = n_lors // n_subsets\n",
    "    \n",
    "    print(f\"\\nStarting OSEM on GPU: {n_iterations} iterations, {n_subsets} subsets\")\n",
    "    print(f\"Total LORs: {n_lors}, LORs per subset: {subset_size}\")\n",
    "    print(f\"Batch size: {batch_size}\")\n",
    "    \n",
    "    # OSEM loop\n",
    "    for iteration in range(n_iterations):\n",
    "        print(f\"\\nIteration {iteration + 1}/{n_iterations}\")\n",
    "        \n",
    "        for subset in range(n_subsets):\n",
    "            start_idx = subset * subset_size\n",
    "            end_idx = start_idx + subset_size if subset < n_subsets - 1 else n_lors\n",
    "            lors_subset = lors[start_idx:end_idx]\n",
    "            \n",
    "            # Forward projection\n",
    "            expected = forward_project_gpu(lors_subset, image, attenuation_flat,\n",
    "                                          grid_size, voxel_size, grid_origin,\n",
    "                                          batch_size)\n",
    "            \n",
    "            # Compute ratios\n",
    "            expected = np.maximum(expected, 1e-10)\n",
    "            ratios = 1.0 / expected\n",
    "            \n",
    "            # Backprojection\n",
    "            backproj = backproject_gpu(lors_subset, ratios, attenuation_flat,\n",
    "                                      grid_size, voxel_size, grid_origin,\n",
    "                                      batch_size)\n",
    "            \n",
    "            # Update image\n",
    "            image *= backproj / sensitivity\n",
    "            \n",
    "            print(f\"  Subset {subset + 1}/{n_subsets} complete\")\n",
    "    \n",
    "    image_3d = image.reshape(grid_size)\n",
    "    sensitivity_3d = sensitivity.reshape(grid_size)\n",
    "    \n",
    "    return image_3d, sensitivity_3d\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Checking CUDA availability...\")\n",
    "    print(f\"CUDA available: {cuda.is_available()}\")\n",
    "    if cuda.is_available():\n",
    "        print(f\"GPU: {cuda.get_current_device().name.decode()}\")\n",
    "    \n",
    "    # Generate example data\n",
    "    print(\"\\nGenerating example data...\")\n",
    "    \n",
    "    # Simple phantom\n",
    "    phantom = np.zeros((128, 128, 128), dtype=np.float32)\n",
    "    for i in range(128):\n",
    "        for j in range(128):\n",
    "            for k in range(128):\n",
    "                r = np.sqrt((i-64)**2 + (j-64)**2 + (k-64)**2)\n",
    "                if r < 30:\n",
    "                    phantom[i, j, k] = 1.0\n",
    "    \n",
    "    # Run OSEM on GPU\n",
    "    reconstructed, sensitivity = osem_reconstruct_gpu(\n",
    "        lors, attenuation,\n",
    "        n_subsets=10,\n",
    "        n_iterations=3,\n",
    "        batch_size=1000000  # Adjust if you get memory errors\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nReconstruction complete!\")\n",
    "    print(f\"Image shape: {reconstructed.shape}\")\n",
    "    print(f\"Image range: [{reconstructed.min():.3f}, {reconstructed.max():.3f}]\")\n",
    "\n",
    "    # Display central slice\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.imshow(reconstructed[:, :, 64], cmap='hot')\n",
    "    plt.colorbar()\n",
    "    plt.title('Central Slice of Reconstructed Image on GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c25cba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import cuda\n",
    "\n",
    "@cuda.jit\n",
    "def conditional_kernel(A, B, C):\n",
    "    i = cuda.grid(1)\n",
    "    \n",
    "    if i < A.size:\n",
    "        val_a = A[i]\n",
    "        val_b = B[i]\n",
    "        \n",
    "        # Your Logic:\n",
    "        # If both are < 0.5, add them.\n",
    "        if val_a < 0.5 and val_b < 0.5:\n",
    "            C[i] = val_a + val_b\n",
    "        else:\n",
    "            # Otherwise, subtract the greater from the lesser (lesser - greater)\n",
    "            if val_a > val_b:\n",
    "                C[i] = val_b - val_a\n",
    "            else:\n",
    "                C[i] = val_a - val_b\n",
    "\n",
    "def main():\n",
    "    n = 1_000_000\n",
    "    \n",
    "    # 1. Generate random values between 0 and 1\n",
    "    host_a = np.random.random(n).astype(np.float32)\n",
    "    host_b = np.random.random(n).astype(np.float32)\n",
    "    host_c = np.zeros(n, dtype=np.float32)\n",
    "\n",
    "    # 2. Move to GPU\n",
    "    device_a = cuda.to_device(host_a)\n",
    "    device_b = cuda.to_device(host_b)\n",
    "    device_c = cuda.to_device(host_c)\n",
    "\n",
    "    # 3. Configure Grid\n",
    "    threads_per_block = 256\n",
    "    blocks_per_grid = (n + (threads_per_block - 1)) // threads_per_block\n",
    "\n",
    "    # 4. Launch\n",
    "    conditional_kernel[blocks_per_grid, threads_per_block](device_a, device_b, device_c)\n",
    "\n",
    "    # 5. Bring result back\n",
    "    host_c = device_c.copy_to_host()\n",
    "\n",
    "    # Verify a few samples\n",
    "    for j in range(5):\n",
    "        print(f\"A: {host_a[j]:.3f}, B: {host_b[j]:.3f} -> Result: {host_c[j]:.3f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opengate_scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
